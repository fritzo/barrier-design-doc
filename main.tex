%%%% Small single column format
\documentclass[anonymous=false, %
               format=acmsmall, %
               review=true, %
               screen=true, %
               nonacm=true]{acmart}

\usepackage[ruled]{algorithm2e} 
%\usepackage{parskip}

\urlstyle{tt}
\citestyle{acmauthoryear}

\begin{document}

\title{Delayed Sampling via Funsors and Barriers}
%  \titlenote{This is a titlenote}
%  \subtitle{This is a subtitle}
%  \subtitlenote{Subtitle note}

\author{Fritz Obermeyer}
%\orcid{1234-5678-9012-3456}
\affiliation{%
  \institution{Uber AI}
  %\department{}
  %\streetaddress{43 Vassar St}
  %\city{Cambridge}
  %\state{MA}
  %\postcode{02139}
  %\country{USA}
}
\email{fritzo@uber.com}

\author{Eli Bingham}
%\orcid{1234-5678-9012-3456}
\affiliation{%
  \institution{Uber AI}
  %\streetaddress{625 Mt Auburn St #3}
  %\city{Cambridge}
  %\state{MA}
  %\postcode{02138}
  %\country{USA}
}
\email{eli.bingham@uber.com}
%\renewcommand\shortauthors{Mage, M. et al}

\begin{abstract}
Delayed sampling is an inference technique for automatic Rao-Blackwellization in sequential latent variable models.
Funsors are a software abstraction generalizing Tensors and Distributions and supporting seminumerical computation including analytic integration.
We demonstrate how to easily implement delayed sampling in a Funsor-based probabilistic programming language using effect handlers for \texttt{sample} statements and a \texttt{barrier} statement.
\end{abstract}

\maketitle

\section{Introduction}

Let us distinguish two types of inference strategies in probabilistic programming, call them \emph{lazy} and \emph{eager}.
Let us say a strategy is lazy if it it first symbolically evaluates or compiles model code, then globally analyzes the code to create an inference update strategy.
By contrast consider a strategy eager if it eagerly executes model code, drawing samples from each latent variable.
For example the autograd-based inference algorithms in Pyro \cite{bingham2018pyro} are eager in the sense that samples are eagerly created at each sample site.

However it is often advantageous to combine lazy and eager strategies, performing local exact computations within small parts of a probabilistic model, but drawing samples to communicate between those parts.
Examples include Rao-Blackwellized SMC filters and their generalization as implemented in Birch \cite{murray2017delayed}, and reactive probabilistic programming \cite{baudart2019reactive}.

This work addresses the challenge of implementing boundedly-lazy inference in a Pyro-like language where samples are eagerly drawn and control flow may depend on those sample values.
Our approach is to use Funsors, a software abstraction generalizing Tensors, Distributions, and lazy compute graphs.
The core idea is to allow lazy sample statements during program execution, and to trigger sampling of lazy random variables only at user-specified \verb$barrier$ statements, typically before control flow.
We implement our approach using two effect handlers \cite{moore2018effect,pretnar2015introduction}.

\section{Delayed Sampling}

Delayed sampling \cite{murray2017delayed} is an inference technique for automatic Rao-Blackwellization in sequential latent variable models.
Delayed sampling was introduced in the Birch probabilistic programming language \cite{murray2018automated}.

\section{Funsors}

Funsors \cite{obermeyer2019functional} are a software abstraction generalizing Tensors and Distributions and supporting seminumerical computation including analytic integration.

\section{Delayed Sampling with Funsors}

Consider an embedded probabilistic programming language, extending a host language with two primitive statements.
\begin{itemize}
  \item The statement \verb$x = sample(name,dist)$ is a named stochastic statement, where \verb$x$ is a Funsor value, \verb$name$ is a unique identifier for the statement, and \verb$dist$ is a Funsor distribution.
  \item The statement \verb$x = barrier(x)$ eliminates any free variables from the recursive data structure \verb$x$, which may contain Funsor values.
\end{itemize}
We use Python for the host language in this paper.

We will implement each inference algorithm as an effect handler.
Each inference algorithm will input observed data, allow running of model code, and can then interpret nonstandard model outputs as posterior probability distributions, e.g.
\begin{verbatim}
with MyInferenceAlgorithm(data=observations) as inference:
    output = model()

posterior = inference.get_posterior(output)
\end{verbatim}
where \verb$observations$ is a dictionary mapping sample statement name to observed value, and the resulting \verb$posterior$ is some representation of the posterior distribution over latent variables.

Consider a model of stochastic control system with piecewise control, attempting to keep a latent state \verb$z$ within the interval $[-10,10]$
\begin{verbatim}
 1  def model():
 2      z = sample("z_init",Normal(0,1))  # latent state
 3      k = 0                             # control
 4      cost = 0                          # cumulative cost of controller
 5      for t in range(1000):
 6          if z > 10:                    # control flow depends on z
 7              k -= 1
 8          elif z < -10:
 9              k += 1
10          else:
11              k = 0
12          cost += abs(k)
13          z = sample(f"z_{t}",Normal(z+k,1))
14          x = sample(f"x_{t}",Normal(z,1))
15      return cost
\end{verbatim}
Now suppose we want to estimate the total controller cost given a sequence of observations \verb$x$.
One approach to inference is to apply Sequential Monte Carlo (SMC) filtering.
To maintain a vectorized population of particles we can rewrite the model using a vectorized conditional (e.g. \verb$where(cond,if_true,if_false)$ as implemented in NumPy and PyTorch).
Further we can support resampling of particle populations by adding a \verb$barrier$ statement; this is needed to communicate resampling decisions with the model's local state.
\begin{verbatim}
 1  def model():
 2      z = sample("z_init",Normal(0,1))    # latent state
 3      k = 0 * z                           # control
 4      cost = 0 * z                        # cumulative cost of controller
 5      for t in range(1000):
 6          z,k,cost = barrier((z,k,cost))
 7          k = where(z > 10, k + 1, k)
 8          k = where(z < 10, k + 1, k)
 9          k = where(-10 <= z & z <= 10, 0 * k, k)
10          z = sample(f"z_{t}",Normal(z+k,1))
11          x = sample(f"x_{t}",Normal(z,1))
12      return cost
\end{verbatim}
See appendix \label{sec:appendix:smc} for details of the effect handlers \verb$condition$ and \verb$log_joint$ to implement SMC inference.

Notice that if there were no control \verb$k$ (or indeed if the control were linear), we could completely Rao-Blackwellize using a Kalman filter: inference via variable elimination would be exact.
To implement linear-time exact inference, we require only:
\begin{itemize}
  \item lazy versions of tensor operations such as $where$;
  \item a lazy interpretation for \verb$sample$ statements;
  \item a variable-eliminating interpretation of \verb$barrier$ statements; and
  \item a variable-eliminating computation of the final \verb$log_joint$ latent state.
\end{itemize}
See appendix \label{sec:appendix:exact} for details of the effect handlers \verb$condition$ and \verb$log_joint$ to implement SMC inference.
This is the approach taken by Pyro's discrete enumeration inference, which leverages broadcasting in the host tensor DSL to implement lazy sampling and lazy tensor ops.

To partially Rao-Blackwellize our SMC inference, we can combine the two approaches, emitting lazily sampled values from \verb$sample$ statements and eagerly sampling delayed samples at \verb$barrier$ statements.
In contrast to the variable-elimination interpretation of \verb$barrier$, this interpretation guarantees all local state is ground and hence can be inspected by conditionals.
See appendix \label{sec:appendix:delayed} for details of effect handlers \verb$condition$ and \verb$log_joint$ to implement delayed sampling.

\section{Conclusion}

We demonstrated flexible inference algorithms in an embedded probabilistic programming language with a new \verb$barrier$ statement and support for lazy computations represented as Funsors.
While Funsor implementations are few, this same technique can be used for delayed sampling of discrete latent variables using only a Tensor library.

% See Lawrence's paper for examples including
% * linear+nonlinear Gaussian state space model and
% * Beta-Binomial-Poisson vector-borne disease model
% https://arxiv.org/pdf/1708.07787.pdf

\bibliographystyle{acm-reference-format}
\bibliography{main}

\section{Appendix: Details of effect handling}

\subsection{Effect handling framework}
Before describing effect implementations, we provide a simple framework for effect handling embedded in Python.
Let's start with a standard interpretation, also implemented as an effect handler.
\begin{verbatim}
class StandardHandler:
    def __enter__(self):
        global HANDLER
        self.old_handler = HANDLER
        HANDLER = self
        return self

    def __exit__(self, type, value, traceback):
        global HANDLER
        HANDLER = self.old_handler

    def sample(self, name, dist):
        return dist.sample()

    def barrier(self, state):
        return state

HANDLER = StandardHandler()

def sample(name, dist):
    return HANDLER.sample(name, dist)

def barrier(state):
    return HANDLER.barrier(state)
\end{verbatim}
Note that the global \verb$sample$ and \verb$barrier$ statements are late binding.

\subsection{Effect handlers for inference via Sequential Monte Carlo}
\label{sec:appendix:smc}
We can now implement Sequential Monte Carlo inference by maintaining a vector \verb$log_joint$ of particle log weights, multiply sampling at \verb$sample$ statements, and resampling at \verb$barrier$ statements.
\begin{verbatim}
class SMC(StandardHandler):
    def __init__(self, data, num_particles=100):
        self.data = data
        self.log_joint = zeros(num_particles)
        self.num_particles = num_particles

    def sample(self, name, dist):
        if name in self.data:
            value = self.data[name]
        else:
            value = dist.sample(sample_shape=self.log_joint.shape)
        self.log_joint += dist.log_prob(self.data[name])
        return value

    def barrier(self, state):
        index = Categorical(logits=self.log_joint).sample()
        self.log_joint[:] = 0
        return [x[index] for x in state]

    def get_posterior(self, value):
        probs = exp(self.log_joint)
        probs /= probs.sum()
        return {"samples": value, "probs": probs}
\end{verbatim}

\subsection{Effect handlers for exact inference via Variable Elimination}
We can implement variable elimination by leveraging lazy compute graphs and exact forward-backward computation of the Funsor library.
\label{sec:appendix:exact}
\begin{verbatim}
class VariableElimination(StandardHandler):
    def __init__(self, data, num_particles=100):
        self.data = data
        self.log_joint = funsor.Number(0)
        self.num_particles = num_particles

    def sample(self, name, dist):
        if name in self.data:
            value = self.data[name]
        else:
            value = funsor.Variable(name)  # create a delayed sample
        self.log_joint += dist.log_prob(self.data[name])
        return value

    def get_posterior(self, value):
        subs = self.log_joint.sample(self.num_particles)
        return value(**subs)
\end{verbatim}

\subsection{Effect handlers for inference via Delayed Sampling}
We can now implement delayed sampling by extending the \verb$VariableElimination$ handler to eagerly eliminate variables whenever a barrier statement is encountered.
\label{sec:appendix:delayed}
\begin{verbatim}
class DelayedSampling(VariableElimination):
    def barrier(self, state):
        subs = self.log_joint.sample(state.inputs, self.num_samples)
        self.log_joint = self.log_joint(**subs)
        return [x(**subs) for x in state]
\end{verbatim}

\end{document}
